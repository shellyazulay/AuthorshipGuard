import json
import joblib

# Load the previously trained author classification model
model = joblib.load("exp_main/models/author_classifier.joblib")

# Path to the output file from the first stage (DetectGPT, etc.)
input_file = "exp_main/results/xsum_gpt-neo-2.7B.npr.json"

# Load the entire dataset from the JSON file
with open(input_file, "r", encoding="utf-8") as f:
    raw_data = json.load(f)

# Extract the list of results from the 'raw_results' key
data = raw_data["raw_results"]

results = []
# Iterate over each entry in the dataset
for entry in data:
    # Get the 'sampled' text from the entry (fall back to empty string if missing)
    text = entry.get("sampled", "")
    # Predict the author based on the text
    predicted_author = model.predict([text])[0]
    # Append the text and predicted author to the results list
    results.append({
        "text": text,
        "predicted_author": predicted_author
    })

# Define the output path for saving the prediction results
output_file = "exp_main/results/xsum_gpt-neo-2.7B_with_authors.json"

# Save the results list to a JSON file with pretty formatting
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"Prediction finished. Results saved to: {output_file}")
